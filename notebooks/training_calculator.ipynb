{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T18:39:33.090672Z",
     "start_time": "2025-11-02T18:39:32.534274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor([ 512, 768, 1024, 1280, 1600])\n",
    "B = (A/768) ** -0.5\n",
    "# Python\n",
    "C = {int(a): float(b) for a, b in zip(A.tolist(), B.tolist())}\n",
    "print(f\"dim by lr scale ratio: {C}\")"
   ],
   "id": "738999f593e1421",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim by lr scale ratio: {512: 1.2247447967529297, 768: 1.0, 1024: 0.866025447845459, 1280: 0.7745966911315918, 1600: 0.6928203701972961}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T19:50:10.398831Z",
     "start_time": "2025-11-02T19:50:09.813968Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "from daisy.daisy_core import next_multiple_of_n\n",
    "\n",
    "def estimate_params(L: int, d: int, V: int, tied_head: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Returns dict with per-layer, embeddings, and total params (in integers and millions).\n",
    "    Formula:\n",
    "      - Attention (Q,K,V,O): 4 * d * d\n",
    "      - d_fc: 4 * d\n",
    "      - MLP: 2 * d * d_fc\n",
    "      - Per-layer â‰ˆ 4d^2 + 3 d d_fc  (defaults to 16 d^2 when d_fc=4d)\n",
    "      - Embeddings: V * d\n",
    "      - Output head: + V * d if untied\n",
    "    \"\"\"\n",
    "    d_fc = 4 * d\n",
    "    mlp = 2 * d * d_fc\n",
    "    attn = 4 * d * d\n",
    "    per_layer = mlp + attn\n",
    "    layers_total = L * per_layer\n",
    "    embed = V * d\n",
    "    head = 0 if tied_head else next_multiple_of_n(V, n=128) * d\n",
    "    ve = 3 * V * d\n",
    "    scalars = 5 * L\n",
    "    total = layers_total + embed + head + ve + scalars\n",
    "    to_m = lambda x: round(x / 1e6, 3)\n",
    "    return {\n",
    "        \"per_layer\": per_layer,\n",
    "        \"per_layer_M\": to_m(per_layer),\n",
    "        \"layers_total\": layers_total,\n",
    "        \"layers_total_M\": to_m(layers_total),\n",
    "        \"embeddings\": embed,\n",
    "        \"embeddings_M\": to_m(embed),\n",
    "        \"output_head\": head,\n",
    "        \"output_head_M\": to_m(head),\n",
    "        \"total\": total,\n",
    "        \"total_M\": to_m(total),\n",
    "    }"
   ],
   "id": "70f28c3dc5ac3c1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T19:53:11.467215Z",
     "start_time": "2025-11-02T19:53:11.459696Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"embeddings\": 25731584,\n",
      "  \"embeddings_M\": 25.732,\n",
      "  \"layers_total\": 18874368,\n",
      "  \"layers_total_M\": 18.874,\n",
      "  \"output_head\": 25755648,\n",
      "  \"output_head_M\": 25.756,\n",
      "  \"per_layer\": 3145728,\n",
      "  \"per_layer_M\": 3.146,\n",
      "  \"total\": 147556382,\n",
      "  \"total_M\": 147.556\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "import json\n",
    "from training.hparams import load_hparams_from_yaml\n",
    "hparams = load_hparams_from_yaml(\"../config/pretrain_pico.yml\")\n",
    "L = hparams.num_layers\n",
    "d = hparams.model_dim\n",
    "V = hparams.vocab_size\n",
    "res = estimate_params(L=L, d=d, V=V, tied_head=False)\n",
    "print(json.dumps(res, indent=2, sort_keys=True))"
   ],
   "id": "df1f7c86c06b686f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T18:59:55.357036Z",
     "start_time": "2025-10-20T18:59:55.355165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_param_data_ratio = 20\n",
    "num_params = 350\n",
    "target_tokens = target_param_data_ratio * num_params\n",
    "print(f\"Target tokens (M): {target_tokens}\")"
   ],
   "id": "8c461d4b295c1d32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target tokens (M): 7000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T18:59:55.385521Z",
     "start_time": "2025-10-20T18:59:55.383342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scale = 0.866025447845459\n",
    "head_lr = 0.004 * scale\n",
    "embed_lr = 0.2 * scale\n",
    "scalar_lr = 0.015 * scale\n",
    "\n",
    "print(f\"Head LR: {head_lr}\")\n",
    "print(f\"Embed LR: {embed_lr}\")\n",
    "print(f\"Scalar LR: {scalar_lr}\")\n"
   ],
   "id": "18b1710a80f2eae4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head LR: 0.003464101791381836\n",
      "Embed LR: 0.1732050895690918\n",
      "Scalar LR: 0.012990381717681885\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T19:16:40.111429Z",
     "start_time": "2025-10-20T19:16:40.108975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sft_scale = 1/50\n",
    "print(f\"Head LR: {head_lr*sft_scale}\")\n",
    "print(f\"Embed LR: {embed_lr*sft_scale}\")\n",
    "print(f\"Scalar LR: {scalar_lr*sft_scale}\")"
   ],
   "id": "5c6607943869af84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head LR: 6.928203582763672e-05\n",
      "Embed LR: 0.003464101791381836\n",
      "Scalar LR: 0.0002598076343536377\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T19:22:04.599764Z",
     "start_time": "2025-10-20T19:22:04.596847Z"
    }
   },
   "cell_type": "code",
   "source": "0.015 * sft_scale",
   "id": "de17d1459ebc7468",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
