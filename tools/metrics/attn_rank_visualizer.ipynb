{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c31ed4d591a20e9",
   "metadata": {},
   "source": [
    "# Attention Rank Visualizer — per head or whole layer\n",
    "\n",
    "This notebook is an implementation of concepts in the paper [When Attention Collapses: How Degenerate Layers in LLMs Enable Smaller, Stronger Models](https://arxiv.org/html/2404.08634v3).\n",
    "\n",
    "**Methodology**\n",
    "1. Build the attention matrix `A` (H,T,T) across all heads in the `CausalSelfAttention` module from a chosen layer ([see attn_rank.py line 14](attn_rank.py#L14))\n",
    "2. For each head:\n",
    "    - calculate an **effective rank**: the smallest `k` whose top singular values explain **90%** of the matrix energy ([see attn_rank.py line 45](attn_rank.py#L45))\n",
    "    - measure **single‑column‑ness**: the fewest columns needed to cover **90%** of the squared entries of `A` ([see attn_rank.py line 55](attn_rank.py#L55))\n",
    "3. Plot the heatmaps of each `A` and a per‑head rank profile [Go to heatmaps section](#heatmaps-of-attention-matrices-per-layer)\n",
    "4. Compute averages over N sequences of length T [Go to batch section](#batch-over-multiple-sequences) - the paper uses `N=100` and `T=100` to offer a more stable estimate of the rank profile\n",
    "\n",
    "\n",
    "**Technical Notes**\n",
    "- `models.gpt2.attention.CausalSelfAttention` uses merged QKVO weights in `qkvo_w` of shape `(4, num_heads*head_dim, dim)`\n",
    "- hidden states `X` of shape `(B, T, dim)` that enter an attention block (from the previous layer) are exposed in `CausalSelfAttention` as `in_t` for convenience\n",
    "\n",
    "**Note**: Start with short sequences (e.g., `T ≤ 128`) because SVD (Singular Value Decomposition) scales cubically with `T`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6837be1d58919",
   "metadata": {},
   "source": "# Helpers"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:02.697388Z",
     "start_time": "2025-10-16T16:24:01.938558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models.gpt2.block\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=True)"
   ],
   "id": "1d871b19a845bf68",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c141280cacb35d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:02.705879Z",
     "start_time": "2025-10-16T16:24:02.703064Z"
    }
   },
   "source": [
    "def show_attention_heatmap(A: torch.Tensor, head: int=0, title: str=None):\n",
    "    \"\"\"A: (H, T, T) or (T, T).\"\"\"\n",
    "    plt.figure()\n",
    "    if A.dim() == 3:\n",
    "        M = A[head].detach().cpu().numpy()\n",
    "    else:\n",
    "        M = A.detach().cpu().numpy()\n",
    "    plt.imshow(M, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Key position j')\n",
    "    plt.ylabel('Query position i')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_head_ranks(ranks, title: str='Effective rank (90%) per head'):\n",
    "    plt.figure()\n",
    "    xs = list(range(len(ranks)))\n",
    "    plt.plot(xs, ranks, marker='o')\n",
    "    plt.xlabel('Head index')\n",
    "    plt.ylabel('Rank-90%')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_head_masses(masses, title: str='Fewest columns for 90% mass per head'):\n",
    "    plt.figure()\n",
    "    xs = list(range(len(masses)))\n",
    "    plt.plot(xs, masses, marker='o')\n",
    "    plt.xlabel('Head index')\n",
    "    plt.ylabel('#columns for 90% mass')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "83ca2d6ae08e9559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:05.975255Z",
     "start_time": "2025-10-16T16:24:02.708918Z"
    }
   },
   "source": [
    "from models.gpt2 import GPT2Core\n",
    "from tools.metrics.attn_rank import attention_matrix_from_attn, per_head_metrics, average_per_head_over_sequences\n",
    "from training.data_gen import DistributedDataGenerator\n",
    "from tools.checkpoint import model_from_checkpoint\n",
    "\n",
    "pt = \"/Users/jonathanmiddleton/models/checkpoints/350m-instruct/20251013T1953-val1.600-step000850-run1-best.pt\"\n",
    "device = 'cpu'\n",
    "seq_len = 100 # 100 in paper\n",
    "\n",
    "data_loader = DistributedDataGenerator(\n",
    "    \"../../data/fineweb/fineweb_val_000000.bin\",\n",
    "    1 * seq_len,\n",
    "    rank = 0,\n",
    "    world_size=1,\n",
    "    device=device,\n",
    ")\n",
    "# noinspection PyTypeChecker\n",
    "model: GPT2Core = model_from_checkpoint(pt, device=device, map_location=device).eval()\n",
    "p = next(data_loader)[0][None,:] # one sample\n",
    "with torch.no_grad():\n",
    "    model.prefill_batch(p, 256)\n",
    "\n",
    "def build_attention_matrix(layer_id):\n",
    "    with torch.no_grad():\n",
    "        # noinspection PyTypeChecker\n",
    "        attn: models.gpt2.CausalSelfAttention = model.blocks[layer_id].attn\n",
    "        X: torch.Tensor = attn.in_t.squeeze(0) # (T, dim)\n",
    "        return attention_matrix_from_attn(attn, X)\n",
    "\n",
    "def compute_and_visualize(layer_id: int):\n",
    "    with torch.no_grad():\n",
    "        A = build_attention_matrix(layer_id)\n",
    "        for h in range(A.shape[0]):\n",
    "            show_attention_heatmap(A, head=h, title=f'Attention matrix — head {h}')\n",
    "        ranks, masses, max_rank = per_head_metrics(A, device=device)\n",
    "        print('Per‑head effective ranks:', ranks)\n",
    "        print('Per‑head columns@90%:', masses)\n",
    "        print('MaxRank(layer) =', max_rank)\n",
    "        plot_head_ranks(ranks)\n",
    "        plot_head_masses(masses)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "f6444570a3d84e76",
   "metadata": {},
   "source": "# Heatmaps of Attention matrices per layer"
  },
  {
   "cell_type": "code",
   "id": "196632ebc3e33438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:06.025456Z",
     "start_time": "2025-10-16T16:24:05.998945Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "_layer_dropdown = widgets.Dropdown(\n",
    "    options=list(range(len(model.blocks))),\n",
    "    value=0,\n",
    "    description='Layer:',\n",
    ")\n",
    "_run_button = widgets.Button(description='Run', button_style='primary')\n",
    "_out = widgets.Output()\n",
    "\n",
    "display(widgets.HBox([_layer_dropdown, _run_button]), _out)\n",
    "\n",
    "def _on_run_clicked(_):\n",
    "    _run_button.disabled = True\n",
    "    _run_button.description = \"Running...\"\n",
    "    _run_button.button_style = 'info'\n",
    "    try:\n",
    "        with _out:\n",
    "            clear_output(wait=True)\n",
    "            compute_and_visualize(int(_layer_dropdown.value))\n",
    "    finally:\n",
    "        _run_button.disabled = False\n",
    "        _run_button.description = \"Run\"\n",
    "        _run_button.button_style = 'primary'\n",
    "\n",
    "_run_button.on_click(_on_run_clicked)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(Dropdown(description='Layer:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35ec1d7ee10342e8bf18361a27438653"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a1b9ea0055c4910a335b5bdd98f2ffe"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "37818c450beb2844",
   "metadata": {},
   "source": [
    "# Batch over multiple sequences\n",
    "Averaged over `N` sequences of length `T`.\n",
    "- Mirroring the paper's setup: sample `N=100` sequences with `T=100`, then compute per‑head averages and finally `MaxRank(l)` as the maximum head rank per layer.\n",
    "- To inspect a **single‑column** pattern directly, sort the columns of `A[h]` by their squared mass and see if the first one dominates.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8a638b6cc43253f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:06.034475Z",
     "start_time": "2025-10-16T16:24:06.032067Z"
    }
   },
   "source": [
    "def list_f(l: list) -> str:\n",
    "    return \"[\" + \", \".join(f\"{v:.2f}\" for v in l) + \"]\"\n",
    "\n",
    "def compute_batch(layer_id: int):\n",
    "    with torch.no_grad():\n",
    "        I = [inputs[None,:] for inputs, _ in (next(data_loader) for _ in range(seq_len))]\n",
    "        Xs = [model.blocks[layer_id].attn.in_t[0] for inputs in I for _ in model.prefill_batch(inputs, seq_len)]\n",
    "\n",
    "        avgs = average_per_head_over_sequences(model.blocks[layer_id].attn, Xs, device=device)\n",
    "        print(\"avg_ranks_per_head: \", list_f(avgs['avg_ranks_per_head']))\n",
    "        print(\"avg_columns90_per_head: \", list_f(avgs['avg_columns90_per_head']))\n",
    "        print(f\"MaxRank_layer: {avgs['MaxRank_layer']:.2f}\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "83be0b07968f7de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T16:24:06.048546Z",
     "start_time": "2025-10-16T16:24:06.044263Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "_layer_dropdown_batch = widgets.Dropdown(\n",
    "    options=list(range(len(model.blocks))),\n",
    "    value=0,\n",
    "    description='Layer:',\n",
    ")\n",
    "_run_button_batch = widgets.Button(description='Run', button_style='primary')\n",
    "_out_batch = widgets.Output()\n",
    "\n",
    "def _on_run_clicked_batch(_):\n",
    "    _run_button_batch.button_style = 'info'\n",
    "    _run_button_batch.description = \"Running...\"\n",
    "    _run_button_batch.disabled = True\n",
    "    try:\n",
    "        with _out_batch:\n",
    "            clear_output(wait=True)\n",
    "            compute_batch(int(_layer_dropdown_batch.value))\n",
    "    finally:\n",
    "        _run_button_batch.button_style = 'primary'\n",
    "        _run_button_batch.description = \"Run\"\n",
    "        _run_button_batch.disabled = False\n",
    "\n",
    "try:\n",
    "    _run_button_batch.on_click(_on_run_clicked_batch, remove=True)\n",
    "except Exception:\n",
    "    pass\n",
    "_run_button_batch.on_click(_on_run_clicked_batch)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([_layer_dropdown_batch, _run_button_batch]),\n",
    "    _out_batch\n",
    "]))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Layer:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8a582f6f0d9473a8d612d9c961cc9a6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
