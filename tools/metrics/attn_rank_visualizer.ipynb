{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c31ed4d591a20e9",
   "metadata": {},
   "source": [
    "# Attention Rank Visualizer — per head or whole layer\n",
    "\n",
    "This notebook is an implementation of concepts in the paper [When Attention Collapses: How Degenerate Layers in LLMs Enable Smaller, Stronger Models](https://arxiv.org/html/2404.08634v3).\n",
    "\n",
    "**Methodology**\n",
    "1. Build the attention matrix `A` (H,T,T) across all heads in the `CausalSelfAttention` module from a chosen layer ([see attn_rank.py line 14](attn_rank.py#L14))\n",
    "2. For each head:\n",
    "    - calculate an **effective rank**: the smallest `k` whose top singular values explain **90%** of the matrix energy ([see attn_rank.py line 45](attn_rank.py#L45))\n",
    "    - measure **single‑column‑ness**: the fewest columns needed to cover **90%** of the squared entries of `A` ([see attn_rank.py line 55](attn_rank.py#L55))\n",
    "3. Plot the heatmaps of each `A` and a per‑head rank profile [Go to heatmaps section](#heatmaps-of-attention-matrices-per-layer)\n",
    "4. Compute averages over N sequences of length T [Go to batch section](#batch-over-multiple-samples) - the paper uses `N=100` and `T=100` to offer a more stable estimate of the rank profile\n",
    "\n",
    "\n",
    "**Technical Notes**\n",
    "- `models.gpt2.attention.CausalSelfAttention` uses merged QKVO weights in `qkvo_w` of shape `(4, num_heads*head_dim, dim)`\n",
    "- hidden states `X` of shape `(B, T, dim)` that enter an attention block (from the previous layer) are exposed in `CausalSelfAttention` as `in_t` for convenience\n",
    "\n",
    "**Note**: Start with short sequences (e.g., `T ≤ 128`) because SVD (Singular Value Decomposition) scales cubically with `T`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6837be1d58919",
   "metadata": {},
   "source": "# Helpers"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:39:54.461621Z",
     "start_time": "2025-10-16T19:39:53.779317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models.gpt2.block\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=True)"
   ],
   "id": "1d871b19a845bf68",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c141280cacb35d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:39:54.494556Z",
     "start_time": "2025-10-16T19:39:54.465014Z"
    }
   },
   "source": [
    "def show_attention_heatmap(A: torch.Tensor, head: int=0, title: str=None):\n",
    "    \"\"\"A: (H, T, T) or (T, T).\"\"\"\n",
    "    plt.figure()\n",
    "    if A.dim() == 3:\n",
    "        M = A[head].detach().cpu().numpy()\n",
    "    else:\n",
    "        M = A.detach().cpu().numpy()\n",
    "    plt.imshow(M, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Key position j')\n",
    "    plt.ylabel('Query position i')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_head_ranks(ranks, title: str='Effective rank (90%) per head'):\n",
    "    plt.figure()\n",
    "    xs = list(range(len(ranks)))\n",
    "    plt.plot(xs, ranks, marker='o')\n",
    "    plt.xlabel('Head index')\n",
    "    plt.ylabel('Rank-90%')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_head_masses(masses, title: str='Fewest columns for 90% mass per head'):\n",
    "    plt.figure()\n",
    "    xs = list(range(len(masses)))\n",
    "    plt.plot(xs, masses, marker='o')\n",
    "    plt.xlabel('Head index')\n",
    "    plt.ylabel('#columns for 90% mass')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def compute_and_visualize(model, data_loader, layer_id: int):\n",
    "    with torch.no_grad():\n",
    "        p = next(data_loader)[0][None,:]\n",
    "        model.prefill_batch(p, 256, debug=True)\n",
    "        attn = model.blocks[layer_id].attn\n",
    "        A = attention_matrix_from_attn(attn)\n",
    "        for h in range(A.shape[0]):\n",
    "            show_attention_heatmap(A, head=h, title=f'Attention matrix — head {h}')\n",
    "        ranks, masses, max_rank = per_head_metrics(A, device=device)\n",
    "        print('Per‑head effective ranks:', ranks)\n",
    "        print('Per‑head columns@90%:', masses)\n",
    "        print('MaxRank(layer) =', max_rank)\n",
    "        plot_head_ranks(ranks)\n",
    "        plot_head_masses(masses)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model and Loader",
   "id": "764fffaba3e724c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:39:57.477940Z",
     "start_time": "2025-10-16T19:39:54.497565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.gpt2 import GPT2Core\n",
    "from tools.metrics.attn_rank import attention_matrix_from_attn, per_head_metrics, average_per_head_over_sequences\n",
    "from training.data_gen import DistributedDataGenerator\n",
    "from tools.checkpoint import model_from_checkpoint\n",
    "\n",
    "pt = \"/Users/jonathanmiddleton/models/checkpoints/350m-instruct/20251013T1953-val1.600-step000850-run1-best.pt\"\n",
    "device = 'cpu'\n",
    "seq_len = 100 # 100 in paper\n",
    "\n",
    "data_loader = DistributedDataGenerator(\n",
    "    \"../../data/fineweb/fineweb_val_000000.bin\",\n",
    "    1 * seq_len,\n",
    "    rank = 0,\n",
    "    world_size=1,\n",
    "    device=device,\n",
    ")\n",
    "# noinspection PyTypeChecker\n",
    "model: GPT2Core = model_from_checkpoint(pt, device=device, map_location=device).eval()"
   ],
   "id": "cd7dd3c618cf2445",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "f6444570a3d84e76",
   "metadata": {},
   "source": "# Heatmaps of Attention matrices per layer"
  },
  {
   "cell_type": "code",
   "id": "196632ebc3e33438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:39:57.525466Z",
     "start_time": "2025-10-16T19:39:57.499891Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "_layer_dropdown = widgets.Dropdown(\n",
    "    options=list(range(len(model.blocks))),\n",
    "    value=0,\n",
    "    description='Layer:',\n",
    ")\n",
    "_run_button = widgets.Button(description='Run', button_style='primary')\n",
    "_out = widgets.Output()\n",
    "\n",
    "display(widgets.HBox([_layer_dropdown, _run_button]), _out)\n",
    "\n",
    "def _on_run_clicked(_):\n",
    "    _run_button.disabled = True\n",
    "    _run_button.description = \"Running...\"\n",
    "    _run_button.button_style = 'info'\n",
    "    try:\n",
    "        with _out:\n",
    "            clear_output(wait=True)\n",
    "            compute_and_visualize(model, data_loader, int(_layer_dropdown.value))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        _run_button.disabled = False\n",
    "        _run_button.description = \"Run\"\n",
    "        _run_button.button_style = 'primary'\n",
    "\n",
    "_run_button.on_click(_on_run_clicked)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(Dropdown(description='Layer:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fb69e27c8844bf980c8c4f69f2818c6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bcda29b21094ea18fc780b341db83d2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "37818c450beb2844",
   "metadata": {},
   "source": [
    "# Batch over multiple samples\n",
    "Averaged over `N` sequences of length `T`.\n",
    "- Mirroring the paper's setup: sample `N=100` sequences with `T=100`, then compute per‑head averages and finally `MaxRank(l)` as the maximum head rank per layer.\n",
    "- To inspect a **single‑column** pattern directly, sort the columns of `A[h]` by their squared mass and see if the first one dominates.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8a638b6cc43253f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:39:57.531453Z",
     "start_time": "2025-10-16T19:39:57.529144Z"
    }
   },
   "source": [
    "samples = 100 # 100 in paper\n",
    "def list_f(l: list) -> str:\n",
    "    return \"[\" + \", \".join(f\"{v:.2f}\" for v in l) + \"]\"\n",
    "\n",
    "def compute_batch(layer_id: int):\n",
    "    with torch.no_grad():\n",
    "        I = [inputs[None,:] for inputs, _ in (next(data_loader) for _ in range(samples))]\n",
    "        avgs = average_per_head_over_sequences(model, I, layer_id, device=device)\n",
    "        print(\"avg_ranks_per_head: \", list_f(avgs['avg_ranks_per_head']))\n",
    "        print(\"avg_columns90_per_head: \", list_f(avgs['avg_columns90_per_head']))\n",
    "        print(f\"MaxRank_layer: {avgs['MaxRank_layer']:.2f}\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "83be0b07968f7de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T19:40:18.019901Z",
     "start_time": "2025-10-16T19:39:57.542022Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "_layer_dropdown_batch = widgets.Dropdown(\n",
    "    options=list(range(len(model.blocks))),\n",
    "    value=0,\n",
    "    description='Layer:',\n",
    ")\n",
    "_run_button_batch = widgets.Button(description='Run', button_style='primary')\n",
    "_out_batch = widgets.Output()\n",
    "\n",
    "def _on_run_clicked_batch(_):\n",
    "    _run_button_batch.button_style = 'info'\n",
    "    _run_button_batch.description = \"Running...\"\n",
    "    _run_button_batch.disabled = True\n",
    "    try:\n",
    "        with _out_batch:\n",
    "            clear_output(wait=True)\n",
    "            compute_batch(int(_layer_dropdown_batch.value))\n",
    "    finally:\n",
    "        _run_button_batch.button_style = 'primary'\n",
    "        _run_button_batch.description = \"Run\"\n",
    "        _run_button_batch.disabled = False\n",
    "\n",
    "try:\n",
    "    _run_button_batch.on_click(_on_run_clicked_batch, remove=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "_run_button_batch.on_click(_on_run_clicked_batch)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([_layer_dropdown_batch, _run_button_batch]),\n",
    "    _out_batch\n",
    "]))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Layer:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c337e940b2e04f0ab670ef098ee69916"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_ranks_per_head:  [28.19, 20.91, 18.55, 18.11, 13.41, 17.73, 15.03, 21.23]\n",
      "avg_columns90_per_head:  [36.45, 29.73, 28.78, 28.42, 16.03, 25.67, 19.79, 27.40]\n",
      "MaxRank_layer: 28.19\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
