{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Rank Visualizer — per head or whole layer\n",
    "\n",
    "This notebook is based on the paper [When Attention Collapses: How Degenerate Layers in LLMs Enable Smaller, Stronger Models](https://arxiv.org/html/2404.08634v3).\n",
    "\n",
    "1. Build the attention matrix `A` for a chosen head from the `CausalSelfAttention` module.\n",
    "2. Measure an **effective rank**: the smallest `k` whose top singular values explain **90%** of the matrix energy.\n",
    "3. Measure **single‑column‑ness**: the fewest columns needed to cover **90%** of the squared entries of `A`.\n",
    "4. Plot a heatmap of `A` and a per‑head rank profile.\n",
    "\n",
    "**Assumptions**\n",
    "- Uses `models.gpt2.attention.CausalSelfAttention`'s merged QKVO weights in `qkvo_w` of shape `(4, num_heads*head_dim, dim)`.\n",
    "- Hidden states `X` of shape `(T, dim)` that enter this attention block (from the previous layer).\n",
    "\n",
    "**Tip**: Start with short sequences (e.g., `T ≤ 128`) because SVD (Singular Value Decomposition) scales cubically with `T`.\n"
   ],
   "id": "4c31ed4d591a20e9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T02:18:46.382073Z",
     "start_time": "2025-10-16T02:18:45.904760Z"
    }
   },
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models.gpt2.block\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=True)\n"
   ],
   "id": "6647e29f49be4ea1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics: effective rank (90%) and single‑column mass (90%)\n",
    "- **effective_rank90(A)**: the smallest `k` so that the top `k` singular values of `A` explain at least 90% of the squared entries.\n",
    "- **columns90(A)**: the fewest columns needed so that their squared entries sum to at least 90% of the squared entries of `A`.\n",
    "\n",
    "Both are computed per head.\n"
   ],
   "id": "868e52b25d4eceea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Plot helpers",
   "id": "493bb9515511768"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T02:18:46.386959Z",
     "start_time": "2025-10-16T02:18:46.384886Z"
    }
   },
   "source": [
    "def show_attention_heatmap(A: torch.Tensor, head: int=0, title: str=None):\n",
    "    \"\"\"A: (H, T, T) or (T, T).\"\"\"\n",
    "    plt.figure()\n",
    "    if A.dim() == 3:\n",
    "        M = A[head].detach().cpu().numpy()\n",
    "    else:\n",
    "        M = A.detach().cpu().numpy()\n",
    "    plt.imshow(M, aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Key position j')\n",
    "    plt.ylabel('Query position i')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_head_ranks(ranks, title: str='Effective rank (90%) per head'):\n",
    "    plt.figure()\n",
    "    xs = list(range(len(ranks)))\n",
    "    plt.plot(xs, ranks, marker='o')\n",
    "    plt.xlabel('Head index')\n",
    "    plt.ylabel('Rank-90%')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_head_masses(masses, title: str='Fewest columns for 90% mass per head'):\n",
    "    plt.figure()\n",
    "    xs = list(range(len(masses)))\n",
    "    plt.plot(xs, masses, marker='o')\n",
    "    plt.xlabel('Head index')\n",
    "    plt.ylabel('#columns for 90% mass')\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ],
   "id": "8cfe96e800571e09",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T02:18:48.515195Z",
     "start_time": "2025-10-16T02:18:46.389283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt2 import GPT2Core\n",
    "from models.gpt2.attention import CausalSelfAttention\n",
    "from tools.metrics.attn_rank import attention_matrix_from_attn, per_head_metrics, average_per_head_over_sequences\n",
    "from training.data_gen import DistributedDataGenerator\n",
    "from tools.checkpoint import model_from_checkpoint\n",
    "\n",
    "pt = \"/Users/jonathanmiddleton/models/checkpoints/350m-instruct/20251013T1953-val1.600-step000850-run1-best.pt\"\n",
    "device = 'cpu'\n",
    "seq_len = 100 # 100 in paper\n",
    "\n",
    "data_loader = DistributedDataGenerator(\n",
    "    \"../../data/fineweb/fineweb_val_000000.bin\",\n",
    "    1 * seq_len,\n",
    "    rank = 0,\n",
    "    world_size=1,\n",
    "    device=device,\n",
    ")\n",
    "# noinspection PyTypeChecker\n",
    "model: GPT2Core = model_from_checkpoint(pt, device=device, map_location=device).eval()\n",
    "p = next(data_loader)[0][None,:] # one sample\n",
    "with torch.no_grad():\n",
    "    model.prefill_batch(p, 256)\n",
    "\n",
    "def build_attention_matrix(layer_id):\n",
    "    with torch.no_grad():\n",
    "        # noinspection PyTypeChecker\n",
    "        block: models.gpt2.block.Block = model.blocks[layer_id]\n",
    "        X: torch.Tensor = block.in_t.squeeze(0) # (T, dim)\n",
    "        return attention_matrix_from_attn(block.attn, X)\n",
    "\n",
    "def compute_and_visualize(layer_id: int):\n",
    "    with torch.no_grad():\n",
    "        A = build_attention_matrix(layer_id)\n",
    "        for h in range(A.shape[0]):\n",
    "            show_attention_heatmap(A, head=h, title=f'Attention matrix — head {h}')\n",
    "        ranks, masses, max_rank = per_head_metrics(A, device=device)\n",
    "        print('Per‑head effective ranks:', ranks)\n",
    "        print('Per‑head columns@90%:', masses)\n",
    "        print('MaxRank(layer) =', max_rank)\n",
    "        plot_head_ranks(ranks)\n",
    "        plot_head_masses(masses)"
   ],
   "id": "5651e22164ee5a92",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T02:22:14.617584Z",
     "start_time": "2025-10-16T02:22:14.609901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "_layer_dropdown = widgets.Dropdown(\n",
    "    options=list(range(len(model.blocks))),\n",
    "    value=0,\n",
    "    description='Layer:',\n",
    ")\n",
    "_run_button = widgets.Button(description='Run', button_style='primary')\n",
    "_out = widgets.Output()\n",
    "\n",
    "display(widgets.HBox([_layer_dropdown, _run_button]), _out)\n",
    "\n",
    "def _on_run_clicked(_):\n",
    "    _run_button.disabled = True\n",
    "    _run_button.description = \"Running...\"\n",
    "    _run_button.button_style = 'info'\n",
    "    try:\n",
    "        with _out:\n",
    "            clear_output(wait=True)\n",
    "            compute_and_visualize(int(_layer_dropdown.value))\n",
    "    finally:\n",
    "        _run_button.disabled = False\n",
    "        _run_button.description = \"Run\"\n",
    "        _run_button.button_style = 'primary'\n",
    "\n",
    "_run_button.on_click(_on_run_clicked)\n"
   ],
   "id": "d8920fc10d81cc67",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(Dropdown(description='Layer:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68059ce49a564a76b08cc273930f63fe"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f898164e1aa440c08e6b802ffb8a43bf"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Batch over multiple sequences (to average per head)\n",
    "- Mirroring the paper's setup: sample `N=100` sequences with `T=100`, then compute per‑head averages and finally `MaxRank(l)` as the maximum head rank per layer.\n",
    "- To inspect a **single‑column** pattern directly, sort the columns of `A[h]` by their squared mass and see if the first one dominates.\n"
   ],
   "id": "75257ea6c4b308e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T02:18:48.567795Z",
     "start_time": "2025-10-16T02:18:48.565541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_f(l: list) -> str:\n",
    "    return \"[\" + \", \".join(f\"{v:.2f}\" for v in l) + \"]\"\n",
    "\n",
    "def compute_batch(layer_id: int):\n",
    "    with torch.no_grad():\n",
    "        I = [inputs[None,:] for inputs, _ in (next(data_loader) for _ in range(seq_len))]\n",
    "        Xs = [model.blocks[layer_id].in_t[0] for inputs in I for _ in model.prefill_batch(inputs, seq_len)]\n",
    "\n",
    "        avgs = average_per_head_over_sequences(model.blocks[layer_id].attn, Xs, device=device)\n",
    "        print(\"avg_ranks_per_head: \", list_f(avgs['avg_ranks_per_head']))\n",
    "        print(\"avg_columns90_per_head: \", list_f(avgs['avg_columns90_per_head']))\n",
    "        print(f\"MaxRank_layer: {avgs['MaxRank_layer']:.2f}\")"
   ],
   "id": "9ac3dd03345abe52",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T02:19:49.938664Z",
     "start_time": "2025-10-16T02:19:49.932498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "_layer_dropdown_batch = widgets.Dropdown(\n",
    "    options=list(range(len(model.blocks))),\n",
    "    value=0,\n",
    "    description='Layer:',\n",
    ")\n",
    "_run_button_batch = widgets.Button(description='Run', button_style='primary')\n",
    "_out_batch = widgets.Output()\n",
    "\n",
    "def _on_run_clicked_batch(_):\n",
    "    _run_button_batch.button_style = 'info'\n",
    "    _run_button_batch.description = \"Running...\"\n",
    "    _run_button_batch.disabled = True\n",
    "    try:\n",
    "        with _out_batch:\n",
    "            clear_output(wait=True)\n",
    "            compute_batch(int(_layer_dropdown_batch.value))\n",
    "    finally:\n",
    "        _run_button_batch.button_style = 'primary'\n",
    "        _run_button_batch.description = \"Run\"\n",
    "        _run_button_batch.disabled = False\n",
    "\n",
    "try:\n",
    "    _run_button_batch.on_click(_on_run_clicked_batch, remove=True)\n",
    "except Exception:\n",
    "    pass\n",
    "_run_button_batch.on_click(_on_run_clicked_batch)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([_layer_dropdown_batch, _run_button_batch]),\n",
    "    _out_batch\n",
    "]))"
   ],
   "id": "55653f18da070fd9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Layer:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19408d40378f41cd9906e05fb898941d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 7
  }
 ]
}
