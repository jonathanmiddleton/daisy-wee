# ~30M params test model
model_class: models.daisy.daisy_core.DaisyCore
eos_token_id: 50256
vocab_size: 50257
num_layers: 6
num_heads: 4
head_dim: 64
model_dim: 256
window_block_size: 128
attention_window_len: 4096
max_seq_len: 1024
use_value_embeddings: false

# baseline (ve)
# [eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.794362 train_time:404,027ms ema_dloss_per_1e6_tokens:-0.483185
# again
# [eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.788577 train_time:406,818ms ema_dloss_per_1e6_tokens:-0.474695


# ve, autocast bf16


# no ve
# eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.788924 train_time:405,852ms ema_dloss_per_1e6_tokens:-0.437410
# again:
# [eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.789969 train_time:403,340ms ema_dloss_per_1e6_tokens:-0.447629
#


# no ve, autocast bf16



