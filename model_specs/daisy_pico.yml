# Daisy ~2MM param test spec
model_class: models.daisy.daisy_core.DaisyCore
eos_token_id: 50256
vocab_size: 50257
num_layers: 6
num_heads: 4
head_dim: 128
model_dim: 512
window_block_size: 128
attention_window_len: 1024
max_seq_len: 65536
use_value_embeddings: false

# baseline (ve)
# [eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.794362 train_time:404,027ms ema_dloss_per_1e6_tokens:-0.483185
# again
# [eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.788577 train_time:406,818ms ema_dloss_per_1e6_tokens:-0.474695


# ve, autocast bf16


# no ve
# eval] dataset=fineweb-edu steps=10 (global_batch=16384, tot_tokens=163840)
# step:100 tokens:6,553,600/6,569,984 (s=0.9975) fineweb-edu:5.788924 train_time:405,852ms ema_dloss_per_1e6_tokens:-0.437410
# again:
#
#


# no ve, autocast bf16



