# GPT2 350M-ish spec
model_class: models.gpt2.gpt_core.GPT2Core
eos_token_id: 50256
vocab_size: 50257
num_layers: 24
num_heads: 16
head_dim: 64
model_dim: 1024
attention_window_tokens: 3456