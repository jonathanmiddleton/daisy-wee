# GPT2 ~1.6B spec
model_class: models.gpt2.gpt_core.GPT2Core
eos_token_id: 50256
vocab_size: 50257
num_layers: 48
num_heads: 25
head_dim: 64
model_dim: 1600
attention_window_tokens: 3456
